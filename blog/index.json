[
    {
        "ref": "https://harrylee.me/blog/2017-05-29-git-simplified-gitflow/",
        "title": "Git: Simplified GitFlow",
        "section": "blog",
        "date" : "2017.05.26",
        "body": "This post describes a simplified Git branching strategy to software versioning and release. This strategy is a slightly simplified version of GitFLow. This strategy does not contradict GitFlow in terms of software development (you can still use feature/* branches), but rather a slight deviation on the release side of GitFlow.\nIntroduction This branching model is a recommendation to the existing GitFlow for a simpler software release cycle. This model is unbiased in terms of the development workflow, as long as you have a development branch you can use this strategy. If you know GitFlow already, this strategy is simply a slight deviation of it with the removal of hot fix branches.\nDevelopment Dev Branch The development (Dev) branch consists of the latest development commits. Feature branches can be used, but must be merged back to the Dev branch at the end of the day for consistency. Continuous intergration (e.g. running of unit tests) should be implemented on every commit/merge to Dev.\nRelease Candidate Release Candidate Branch The Release Candidate (rc) branch is always branched off Dev and is only carried out when the team agrees on a release. Once a Release Candidate branch is created, no more features can be added to this branch, only bug fixes and minor fixes can be carried out on the branch. Release Branch names have the prefix rc followed by the version number (semantic versioning without the patch). Extra features can still be added to the Dev branch.\nContinuously merge back to Dev Commits on the Release Candidate branch (i.e. bug fixes) should be continuously merged back to Dev, so that fixes are reflected in Dev and is available to other team members. Continuous Integration pipeline should be set up to monitor the tip of the Release Candidate branch.\nMaster Master as a collection of stable merges The Master branch must be treated as your single branch of stability. After critical bug fixes and other minor modifications on the Release Candidate branch are complete and a release is imminent, you can merge into Master.\nMaster will only contain merges from Release Candidate branches. Each commit will be associated with a version tag prefixed by v and followed by the full version number (semantic versioning). Each commit/merge on Master is a stable version in production. Continuous integration pipeline must be set up to monitor Master and should be triggered on each merge to Master.\nFix on release candidates Hot fixes in production are done on the Release Candidate branch that references the version in production. This deviates from GitFlow in that hot fix branches are not used. Once all the bug fixes are completed on the Release Candidate branch, the Release Candidate is then merged back to Master and Dev with a new version tag (Patch).\nRinse and Repeat When a new release has been decided by the team, a new Release Candidate is branched off from Dev. Once a minor version has been merged into Master, the previous Release Candidate branch becomes obsolete and may be safely deleted.\nConclusion This branching strategy ensures that the Dev branch is always cutting edge and at the tip of development and the Master branch is the source of truth and stability. This offers a clean and maintainable git repository since at any given time there are only three main branches. Continuous Integration and Continuous Deployment is made easy with this branching strategy as Release Candidate branches are prefixed with rc and the tip of Master is always the latest stable release.\n"
    }
,
    {
        "ref": "https://harrylee.me/blog/2016-08-23-docker-docker-swarm-with-docker-machine-quick-setup-guide/",
        "title": "Docker: Docker Swarm with Docker Machine Quick Setup Guide",
        "section": "blog",
        "date" : "2016.08.23",
        "body": "Docker already has an official documentation with tutorials and examples on how to go about setting up your own Docker Swarm nodes and cluster. This post is intended for those who have a fundamental grasp on Docker and are too lazy to read the documents. This post includes minimal explanation and focuses primarily on the configuration. It is written to be a series of instructions rather than a full fledged post.\nIntroduction This post outlines the set up of docker-machine to provision remote hosts (Generic and Microsoft Azure). Docker Swarm set up with and without docker-machine is also discussed.\nDocker Machine (Azure)\nDocker Machine (Generic)\nDocker Swarm (Generic)\nDocker Machine Swarm (Generic)\nDocker Machine (Azure) To use Docker Machine to provision hosts on Micorsoft Azure, first make sure that you have the correct subscription ID for your Azure account.\nExecute:\n$ docker-machine create --driver azure \\  --azure-subscription-id xxxx-xxxx-xxxx-xxxx \\  --azure-image canonical:UbuntuServer:16.04.0-LTS:latest \\  --azure-location eastus \\  --azure-resource-group DockerSwarm \\  --azure-size Basic_A0 \\  --azure-open-port 80 \\  dockertemp1 To get the latest osImage for the VM, use Azure CLI and execute:\n$ azure vm image list-skus This will return :\ninfo: Executing command vm image list-skus Location: eastus Publisher: canonical Offer: ubuntuserver + Getting virtual machine image skus (Publisher:\u0026#34;canonical\u0026#34; Offer:\u0026#34;ubuntuserver\u0026#34; Location:\u0026#34;eastus\u0026#34;) data: Publisher Offer sku Location data: --------- ------------ ----------------- -------- data: canonical ubuntuserver 12.04.2-LTS eastus data: canonical ubuntuserver 12.04.3-LTS eastus data: canonical ubuntuserver 12.04.4-LTS eastus data: canonical ubuntuserver 12.04.5-DAILY-LTS eastus data: canonical ubuntuserver 12.04.5-LTS eastus data: canonical ubuntuserver 12.10 eastus data: canonical ubuntuserver 14.04-beta eastus  With Azure, the network security group needs to be configured to open port 2376 to any internal port. The Azure driver should handle this for you.\n Docker Machine (Generic) If you already have a host that is running docker and you want to incorporate it into your docker-machine routine. This section is for you.\nWe need to establish a communication channel first. This part is a bit tricky since we are using SSH as the protocol for communication. You will need to make sure that the machines can talk to each other using SSH.\nIn some cases, you may have to disable login using a password option for the machines. You should try this when you get i/o timeout or similar errors regarding communication issues.\n The machine that is doing the deploying will be referred to as the deployment machine and the machine that is going to be deployed is the host.\n $ docker-machine create \\  --driver generic \\  --generic-ip-address=​\u0026lt;ip address\u0026gt;​ \\  --generic-ssh-key ~/.ssh/id_rsa \\  --generic-ssh-user dockeruser \\  --generic-ssh-port 22 ​\\  \u0026lt;machine name\u0026gt;  ip address is the public ip address of the host. machine name is the name that you give to your docker machine. the ssh public key used is the one in the default location: ~/.ssh/id_rsa.  The docker-machine communicates with the host via port 2376 (default). Ensure that this port is open and not blocked by your firewall.\n Docker Swarm (Generic) Below describes the two methods to create a swarm (generic driver) without using Docker Machine.\nToken Method Hosted Discovery Backend Method (Consul)\nToken To install Swarm on the swarm master:\n$ docker run --rm swarm create Take note of the last line which is a token (cluster ID). Copy to a secure location. It will look something like: 81a20406f6258ab0cad7ceb5768daeac.\nThen install Swarm on the other nodes (hosts):\n$ docker run -d \\  --restart=always swarm join \\  --addr=\u0026lt;ip address\u0026gt;:2376 \\  token://\u0026lt;token\u0026gt;  ip address is the IP address of THIS node. token is the token that was generated from the previous step on the swarm master.  Do the same for every host.\nTo manage the swarm from the Swarm master:\n$ docker run -d swarm manage token://\u0026lt;token\u0026gt; To see if the nodes are connected in the swarm:\n$ docker run --rm swarm list token://\u0026lt;token\u0026gt; Hosted Discovery Backend Install Consul If using the token method is not desired, you can use your own discovery key store. Consul can be used as a key:value store which will act as our discovery backend service. Normally this should be on an independent node, so that downtime of your cluster does not bring down this service too.\nSet up Consul:\n$ docker run -d -p 8500:8500 --name=consul progrium/consul -server -bootstrap  This will start a Consul container that exposes port 8500 for the service.  Now we can use Consul to keep track of all the nodes in the swarm instead of the token.\nJoin Swarm Now we need to add all nodes into the swarm. On each node/host, run:\n$ docker run -d \\  --restart=always \\  --name swarm-agent swarm:1.0.0 join \\  --advertise \u0026lt;node ip\u0026gt;:2376 \\  consul://\u0026lt;consul ip\u0026gt;:8500  node ip is the IP address of the host/node. consul ip is the IP address of the node that is running Consul.  Swarm Master Once all nodes are added to the swarm, we need a way to control and manage the nodes. Swarm master does exactly this. Run swarm master on an existing node or an independent node (recommended).\nTo configure the Swarm master:\n$ docker run -d \\  --restart=always \\  --name swarm-agent-master \\  --tlsverify \\  --tlscacert=/etc/docker/ca.pem \\  --tlscert=/etc/docker/server.pem \\  --tlskey=/etc/docker/server-key.pem \\  --strategy spread \\  -p 3376:3376 \\  -v /etc/docker:/etc/docker swarm:1.0.0 manage \\  -H tcp://0.0.0.0:3376 \\  consul://\u0026lt;consul ip\u0026gt;:8500  where the Swarm master is exposed on port 3376  --tlsverify uses TLS, encrypted communication  --tlscacert --tlscert --tlskey ensure that these SSL certificates exist in the directory   -H tcp://0.0.0.0:3376 means that you can access the swarm master on the same node that it has been started.   consul ip is the IP address of the node that is running Consul.    To attach to the Swarm master:\n$ docker -H tcp://\u0026lt;ip address\u0026gt;:3376 info You can change the DOCKER_HOST environment variable if you don\u0026rsquo;t want to type -H \u0026lt;ip address\u0026gt;:\u0026lt;port\u0026gt; all the time.\n$ export DOCKER_HOST=tcp://\u0026lt;ip address\u0026gt;:3376 Docker Machine Swarm (Generic) This section outlines the creation of a swarm using Docker Machine. You should have a discovery backend configured before starting this section. See Hosted Discovery Backend on how to configure a Consul discovery backend.\nTo configure the Swarm Master:\ndocker-machine create \\ --driver generic \\ --generic-ip-address=​\u0026lt;ip address\u0026gt;​ \\ --generic-ssh-key ~/.ssh/id_rsa \\ --generic-ssh-user dockeruser \\ --generic-ssh-port 22 ​\\ --swarm --swarm-master --swarm-discovery=\u0026lt;consul\u0026gt; \\ --engine-opt=\u0026#34;cluster-store=\u0026lt;consul\u0026gt;\u0026#34; \\ --engine-opt=\u0026#34;cluster-advertise=\u0026lt;ip address\u0026gt;:2376\u0026#34; \u0026lt;machine name\u0026gt;  consul can be \u0026quot;$(docker-machine ip \u0026lt;consul name\u0026gt;):\u0026lt;consul port\u0026gt;\u0026quot;  consul name is the docker name that you have given your consul node consul port is the consul service port: 8500    To configure the Swarm Agent (simply remove --swarm-master):\ndocker-machine create \\ --driver generic \\ --generic-ip-address=​\u0026lt;ip address\u0026gt;​ \\ --generic-ssh-key ~/.ssh/id_rsa \\ --generic-ssh-user dockeruser \\ --generic-ssh-port 22 ​\\ --swarm --swarm-discovery=\u0026lt;consul\u0026gt; \\ --engine-opt=\u0026#34;cluster-store=\u0026lt;consul\u0026gt;\u0026#34; \\ --engine-opt=\u0026#34;cluster-advertise=\u0026lt;ip address\u0026gt;:2376\u0026#34; \u0026lt;machine name\u0026gt; When you run docker-machine ls, you should now see some values in the swarm column:\nNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS dockera - generic Running tcp://40.76.49.229:2376 dockera (master) v1.11.1 dockerb * generic Running tcp://40.76.35.249:2376 dockera v1.11.1 dockerconsul - generic Running tcp://104.41.139.22:2376 v1.11.1 Network Since we have the nodes setup in a swarm, we need to configure Docker Multi-Host Network. This is relatively easy if you have the swarm setup using Docker Machine.\n Set your docker machine to point to swarm master:  $ eval $(docker-machine env --swarm dockera)  Check if you are in the swarm environment by executing docker info, you should see all the connected nodes.\n  Create your overlay network:\n$ docker network create \\ --driver overlay \\ --subnet 10.0.9.0/24 \u0026lt;network name\u0026gt;  always define your subnet, you do not want any conflicts with the existing network that the node is connected to.    Check the network: docker network ls. Your newly created network should be listed.\n  Switch to each swarm agent and run the same command to ensure that all agents are connected to the network.\n  Conclusion Following the above set up yields a simple Docker Swarm cluster. There are easier ways to set up clusters such as using Docker Cloud and Amazon Container Services, but that is beside the point of this post. Setting up a Docker cluster this way allows us to learn by delving into the specifics and get our hands dirty with the internal workings of Docker!\n"
    }
,
    {
        "ref": "https://harrylee.me/blog/2016-06-25-docker-create-your-own-ipsec-l2tp-vpn-container/",
        "title": "Docker: Create your own IPsec/L2TP VPN container",
        "section": "blog",
        "date" : "2016.06.25",
        "body": "To configure your own VPN hosted on your own VPS is not difficult at all, especially when there are numerous configuration scripts lying around the internet. We will set up such a VPN using Docker hosted on a Microsoft Azure VM.\nSet Up Listed below is my set up. You don\u0026rsquo;t have to use the exact set up as me, as the configurations should be the same with any VM (Virtual Machine) running Docker (that\u0026rsquo;s the beauty of Docker!).\n Azure VM running Ubuntu 16.04 Xenial  The size of the Virtual Machine does not matter, so you can choose the cheapest one. You can use other Linux distributions, supported ones are:  Ubuntu 16.04, 14.04, 12.04 Debian 8 Jessie CentOS 7, 6     VM has Port 4500 and 500 open for UDP connections. Latest docker-engine installed Using the IPsec VPN Server on Docker Docker image  Configuration The configuration is extremely simple. You literally just follow the instructions listed on IPsec VPN Server on Docker. I shall summarise it below. The below instructions should be executed on the VM and I assume that you have the set up mentioned above.\n  Pull the image\n$ docker pull hwdsl2/ipsec-vpn-server   Create an environment file in your home directory e.g. (/home/dockeruser/vpn.env) with the following content:\nVPN_IPSEC_PSK=\u0026lt;IPsec pre-shared key\u0026gt; VPN_USER=\u0026lt;VPN Username\u0026gt; VPN_PASSWORD=\u0026lt;VPN Password\u0026gt;   DO NOT put single or double quotes around values, or add space around =. Also, DO NOT use these characters within values: \\ \u0026quot; '\n  Load the IPsec NETKEY kernel module:\n$ sudo modprobe af_key   Change directory to your home directory and execute below:\n$ docker run \\  --name ipsec-vpn-server \\  --env-file ./vpn.env \\  -p 500:500/udp \\  -p 4500:4500/udp \\  -v /lib/modules:/lib/modules:ro \\  -d --privileged \\  hwdsl2/ipsec-vpn-server   Now you have a running VPN!\n  Ports You have to remember to open up the ports (500/UDP and 4500/UDP) in order for this to work. I will describe how to do this for Azure VMs using the Network Security Group settings.\nThe following configuration assumes that your VM was created using Resource Manager and not Classic.\n   In your VM instance, select Settings-\u0026gt;Network interfaces-\u0026gt;Your VM interface.\n  In the Network Interface, select Settings-\u0026gt;Network security group-\u0026gt;Your VM network security group. There should just be one by default.\n  In the Network Security Group, select Settings-\u0026gt;Inbound security rules-\u0026gt;Your rules\n  Add the two ports to your inbound rules: 500/UDP and 4500/UDP\n  Conclusion Now you can go ahead and connect to your newly configured VPN! You can restart or stop your container at any time if you do not want to incur costs when you are not using it. This can all be achieved with one command thanks to Docker!\n"
    }
,
    {
        "ref": "https://harrylee.me/blog/2016-06-20-how-to-use-phpstorm-to-debug-remote-docker-container/",
        "title": "Docker: How to use PhpStorm to debug remote Docker container for Web Development using Xdebug",
        "section": "blog",
        "date" : "2016.06.20",
        "body": "There are many tools that can be used for debugging when developing a web app using PHP. These debugging tools are very useful in a local development environment, you can view the states of variables, indicate line breaks etc. However, these tools become difficult to use when you decide to include Docker in your workflow.\nThis post outlines the configuration needed to incorporate the debugging power of the PhpStorm IDE to your PHP based web app. We will not be using the official Docker Support in PhpStorm. This is because we are not integrating PhpStorm fully with Docker, we are merely using PhpStorm for debugging purposes.\nThis post assumes you have the following set up:\n Using Docker (with the official PHP image) Using PhpStorm (version 10.0.*) Using Docker in a VirtualBox setup either using docker-machine or an Ubuntu VM.  My Set Up The following describes my set up of the development environment. You do not need to use the exact set up, but the configuration to follow assume that you are using this set up.\n A local VirtualBox VM running Ubuntu 16.04 Xenial with the latest docker-engine installed. I did not opt to run Docker using Docker for Mac or Docker Toolbox, I just ssh into my Ubuntu VM and run docker natively from there. My docker containers are based on the LAMP stack. I have PhpStorm installed on my host (not my VM). The PhpStorm project is located in a local folder on my host. This local folder is then mounted as a shared folder on the VirtualBox VM. So changes I make to this folder is reflected in the VM and vice versa. In the VM, this shared folder is also mounted as a volume on the docker container. So: changes in code in PhpStorm is reflected in the VM and hence reflected in the docker container.  Configuration With the above set up, we essentially want to use PhpStorm to debug a remote server.\nThe configuration used in this set up is essentially a summary from these two sources:\n Debug your PHP in Docker with Intellij/PHPStorm and Xdebug Debug your PHP in Docker with Intellij/PHPStorm and Xdebug (forked from the above)    Create your own Dockerfile with your own configuration and add the below to install Xdebug:\n FROM php:5 ... RUN yes | pecl install xdebug \\ \u0026amp;\u0026amp; echo \u0026quot;zend_extension=$(find /usr/local/lib/php/extensions/ -name xdebug.so)\u0026quot; \u0026gt; /usr/local/etc/php/conf.d/xdebug.ini \\ \u0026amp;\u0026amp; echo \u0026quot;xdebug.remote_enable=on\u0026quot; \u0026gt;\u0026gt; /usr/local/etc/php/conf.d/xdebug.ini \\ \u0026amp;\u0026amp; echo \u0026quot;xdebug.remote_autostart=off\u0026quot; \u0026gt;\u0026gt; /usr/local/etc/php/conf.d/xdebug.ini   Build your image\n  Start a container with your image but with the following environment variables:\n XDEBUG_CONFIG: \u0026quot;remote_host=10.0.2.2\u0026quot; PHP_IDE_CONFIG: \u0026quot;serverName=my.local\u0026quot; You can either the run the container with the -e option or in a docker-compose.yml file.    In PhpStorm go to Languages \u0026amp; Frameworks \u0026gt; PHP \u0026gt; Servers \u0026gt; and set the following:  Name should match PHP_IDE_CONFIG previously set You can modify the Host and Port to your own settings (the hostname that you use to ssh to the VM)    All set!\n  Usage  Set a break point in your code base in PhpStorm. Access the web page on your local machine. On the web page navigate to the section where it will trigger the break point. The web page will begin loading and PhpStorm will prompt for your attention. On first run, PhpStorm will ask you to map the directories. Follow the prompts and you are done!  "
    }
,
    {
        "ref": "https://harrylee.me/blog/2016-05-31-ssl-how-to-generate-free-ssl-certificates-with-certbot-let-s-encrypt/",
        "title": "SSL: How to generate free SSL certificates with Certbot (Let's Encrypt)",
        "section": "blog",
        "date" : "2016.05.31",
        "body": "Don\u0026rsquo;t know how to configure SSL certificate? Just started learning about how to deploy your own secure website but don\u0026rsquo;t want to spend money purchasing a SSL certificate? Let\u0026rsquo;s Encrypt (now Certbot) is here to save the day!\nBackground  Let’s Encrypt is a free, automated, and open Certificate Authority.\n Let\u0026rsquo;s Encrypt is an official Certificate Authority. This means that the SSL certificate provided/generated by Let\u0026rsquo;s Encrypt is recognised by all browsers as being legitimate. This is different from self-signed certificates which do not fly if you want HTTPS enabled for your publicly accessible website.\nBefore you begin, it goes without saying that you will have to own the domain that you are generating the certificate for. This post assumes that you have deployed a web server and have shell access to it.\nNote that Let\u0026rsquo;s Encrypt certificates expire every 3 months. So the certificates will have to be renewed before it expires to ensure uninterrupted service.\n Set Up This post assumes that you are obtaining the certificates only. If you want to configure Certbot for your specific web server, you can have a look at this list.\n  Clone the Certbot Github repository.\n  Make certbot-auto executable.\n$ sudo chmod a+x ./certbot-auto   Execute:\n$ sudo ./certbot-auto certonly \\  --standalone \\  --email \u0026lt;your-admin@email.com\u0026gt; \\  -d \u0026lt;your-domain.com\u0026gt;  \u0026lt;your-admin@email.com\u0026gt; is the admin email address that Let\u0026rsquo;s Encrypt will use to communicate with you. \u0026lt;your-domain.com\u0026gt; is the domain that you want to generate the certificate for. You cannot create wild card certificates with Let\u0026rsquo;s Encrypt, but you can tie multiple domains to one certificate. Simply add another -d option with your domain/sub-domain.    Follow the prompts.\n  The certificate will be installed to /etc/letsencrypt/live/your-domain-name/.\n  All done! You can now copy the .pem files to your configuration directory.\n fullchain.pem consists of the server certificate as well as the chain certificate. privkey.pem is the server key.    Troubleshoot If you get an error: setuptools pkg_resources pip wheel failed with error code 1 then run the following:\n$ export LC_ALL=\u0026#34;en_US.UTF-8\u0026#34; $ export LC_CTYPE=\u0026#34;en_US.UTF-8\u0026#34; Conclusion Setting up Let\u0026rsquo;s Encrypt using Certbot is not difficult at all. The only downside for using Let\u0026rsquo;s Encrypt is the 3 months expiration, which can get quite annoying. However, the renewing process can be automated by using a cronjob.\n"
    }
,
    {
        "ref": "https://harrylee.me/blog/2016-05-24-ubuntu-backup-files-regularly-using-rsync-and-cron/",
        "title": "Ubuntu: Backup files regularly using expect, rsync and Cron",
        "section": "blog",
        "date" : "2016.05.24",
        "body": "Want to backup your remote files at regular intervals? This post is for you.\nThis post focuses on: rsync, expect and cron. To access the remote server, I\u0026rsquo;m assuming that you are using ssh (with password authentication) for that. If you use ftp or other protocols, you will have to tweak the instructions a bit. If you are using SSH with public key (well done!), you will have to tweak the rsync command to use public key.\nBackground The idea is to use rsync to copy files from the remote server to your local repository. Since remote servers are normally protected by passwords (or private-public key pairs), we need a way for the terminal to enter the password for us. This is where expect comes in.\n Expect is a natural and intuitive automation scripting language that operates in much the same way humans do when interacting with a system.\n So expect removes the need for human interaction when a password is needed. For a detailed way to use expect see Using Expect Scripts to Automate Tasks.\nWe then use cron to schedule automation of this task. See How To Cron.\nMethod   Create a new file in ~/Documents/, backup.exp, with the contents below:\n#!/usr/bin/expect -f  set timeout 19900 set pass \u0026#34;\u0026lt;mypassword\u0026gt;\u0026#34; spawn rsync -av -e ssh \u0026lt;user\u0026gt;@\u0026lt;ip address\u0026gt;:\u0026lt;/home/user/remote\u0026gt; \u0026lt;\u0026#34;/home/user/backup/remote\u0026#34;\u0026gt; expect \u0026#34;assword\u0026#34; sleep 2 send \u0026#34;$pass\\r\u0026#34; expect -re \u0026#34;total size is\u0026#34; expect -re \u0026#34;$\u0026#34; puts \u0026#34;Successfully backed up!\u0026#34;   replace all the necessary parameters with your own credentials. (Basically everything encased between \u0026lt; \u0026gt;).    Change the permission of the file to be executable:\n$ sudo chmod +x ~/Documents/backup.exp   Run cron:\n$ sudo crontab -e   Place the following line at the end of the file.\n 00 06,12,18,00 * * * /home/user/Documents/backup.exp This basically tells the server to execute the backup.exp script every 6 hours, every day at 6:00 AM, 12:00 PM, 18:00 PM and 00:00 AM. You can change the intervals however you see fit.\n  Conclusion This is really useful if you have your own file server with files that are created/modified regularly. Backing up these files consistently and frequently can give you peace of mind that your files are \u0026ldquo;safer\u0026rdquo; than when you do not have this in place.\n"
    }
,
    {
        "ref": "https://harrylee.me/blog/2015-02-08-ubuntu-suspend-and-reboot-at-specific-times-using-cron/",
        "title": "Ubuntu: Suspend and reboot at specific times using Cron",
        "section": "blog",
        "date" : "2015.02.08",
        "body": "If you have a server at home and you want it to be on only during specific times and not 24/7, this script is for you.\nCron not only is the best tool for this, it also handles scheduled tasks.\n Cron is a system daemon used to execute desired tasks (in the background) at designated times.\n Method   Install Cron on Ubuntu if it is not already installed.\n  Create a new file, suspend_until, in your ~/Documents/ and place the following contents in it. This script is written by Romke van der Meulen.\n#!/bin/bash  # Auto suspend and wake-up script # # Puts the computer on standby and automatically wakes it up at specified time # # Written by Romke van der Meulen \u0026lt;redge.online@gmail.com\u0026gt; # Minor mods fossfreedom for AskUbuntu # # Takes a 24hour time HH:MM as its argument # Example: # suspend_until 9:30 # suspend_until 18:45 # ------------------------------------------------------ # Argument check if [ $# -lt 1 ]; then echo \u0026#34;Usage: suspend_until HH:MM\u0026#34; exit fi # Check whether specified time today or tomorrow DESIRED=$((`date +%s -d \u0026#34;$1\u0026#34;`)) NOW=$((`date +%s`)) if [ $DESIRED -lt $NOW ]; then DESIRED=$((`date +%s -d \u0026#34;$1\u0026#34;` + 24*60*60)) fi # Kill rtcwake if already running sudo killall rtcwake # Set RTC wakeup time # N.B. change \u0026#34;mem\u0026#34; for the suspend option # find this by \u0026#34;man rtcwake\u0026#34; sudo rtcwake -a -m disk -t $DESIRED \u0026amp; # feedback echo \u0026#34;Suspending...\u0026#34; # give rtcwake some time to make its stuff sleep 2 # then suspend # N.B. dont usually require this bit #sudo pm-suspend # Any commands you want to launch after wakeup can be placed here # Remember: sudo may have expired by now # Wake up with monitor enabled N.B. change \u0026#34;on\u0026#34; for \u0026#34;off\u0026#34; if # you want the monitor to be disabled on wake xset dpms force on # and a fresh console clear echo \u0026#34;Good morning!\u0026#34;    Change the permission of the file so that it is executable.\n$ sudo chmod +x ~/Documents/suspend_until   Run crontab.\n$ sudo crontab -e   Place the following line at the end of the file.\n00 02 * * * /home/user/Documents/suspend_until 09:00 This basically tells the server to execute the suspend_until script at 2:00 AM. The 09:00 appended at the end of the line tells the server to wake up at 9:00 AM. The details are all explained in the script.\n  Save the crontab file and reboot.\n  "
    }
,
    {
        "ref": "https://harrylee.me/blog/2015-01-10-ubuntu-sharing-externally-connected-drives-over-network/",
        "title": "Ubuntu: Sharing externally connected drives over network",
        "section": "blog",
        "date" : "2015.01.10",
        "body": "When you have external drives connected to the server, it would be very useful if you can share these drives to users accessing the server as well. This is useful if you have a home media server with externally connected drives.\nThis post aims to share drives that are NTFS formatted and changing the permissions of the mounted drives.\nMethod   Unmount the drive that is connected already and remount to another folder giving permissions to users.\n$ sudo umount -l /dev/sdX1 Where sdX1 is the device ID.\nTo check the device ID, execute:\n$ df or\n$ lsblk Remount to another folder.\n$ sudo mount -t ntfs-3g -o rw /dev/sdX1 /media/path/to/folder This assumes that you are connecting a NTFS formatted drive.\n  Change the permission of the mount point to allow access to users.\n$ sudo chown -R $USER:$USER /media/path/to/folder This gives permission, both read and write, to the logged in user that accesses the drive. You can adjust this accordingly.\n  "
    }
]
